{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing particle filter for pacman tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Weights for each ghost based on how close they are to Pacman\n",
    "def manhattanweights(g1, g2, g3, g4, pc):\n",
    "    w1 = 1 / (abs(g1[0] - pc[0]) + abs(g1[1] - pc[1]) + 1e-7)\n",
    "    w2 = 1 / (abs(g2[0] - pc[0]) + abs(g2[1] - pc[1]) + 1e-7)\n",
    "    w3 = 1 / (abs(g3[0] - pc[0]) + abs(g3[1] - pc[1]) + 1e-7)\n",
    "    w4 = 1 / (abs(g4[0] - pc[0]) + abs(g4[1] - pc[1]) + 1e-7)\n",
    "    return [w1, w2, w3, w4]\n",
    "\n",
    "# Motion model for ghosts\n",
    "def motion_model_ghosts(g,pc,prev_action,allow_motion):\n",
    "\n",
    "    ad = au = ar = al = 1\n",
    "    if g[0] > pc[0]:\n",
    "        al += (g[0] - pc[0])\n",
    "    elif g[0] < pc[0]:\n",
    "        ar += (pc[0] - g[0])\n",
    "    if g[1] > pc[1]:\n",
    "        au += (g[1] - pc[1])\n",
    "    elif g[1] < pc[1]:\n",
    "        ad += (pc[1] - g[1])  \n",
    "\n",
    "    if prev_action == \"r\":\n",
    "        ar = ar * 1.25\n",
    "    elif prev_action == \"l\":\n",
    "        al = al * 1.25\n",
    "    elif prev_action == \"u\":\n",
    "        au = au * 1.25\n",
    "    elif prev_action == \"d\":\n",
    "        ad = ad * 1.25\n",
    "\n",
    "\n",
    "    # normalize probabilities\n",
    "    sum = al + ad + au + ar\n",
    "    p_l = al/sum\n",
    "    p_r = ar/sum\n",
    "    p_u = au/sum\n",
    "    p_d = ad/sum\n",
    "\n",
    "    # Given Dictionary of allowable motions, if cannot move direction, split the probabilities to other directions\n",
    "    if allow_motion['u'] == 0:\n",
    "        p_r += 0.4*p_u\n",
    "        p_l += 0.4*p_u\n",
    "        p_d += 0.2*p_u\n",
    "        p_u = 0\n",
    "    \n",
    "    if allow_motion['d'] == 0:\n",
    "        p_r += 0.4*p_d\n",
    "        p_l += 0.4*p_d\n",
    "        p_u += 0.2*p_u\n",
    "        p_d = 0\n",
    "    \n",
    "    if allow_motion['r'] == 0:\n",
    "        p_u += 0.4*p_r\n",
    "        p_d += 0.4*p_r\n",
    "        p_l += 0.2*p_r\n",
    "        p_r = 0\n",
    "    \n",
    "    if allow_motion['l'] == 0:\n",
    "        p_u += 0.4*p_l\n",
    "        p_d += 0.4*p_l\n",
    "        p_r += 0.2*p_l\n",
    "        p_l = 0\n",
    "        \n",
    "    # Returns Probabilties of motion in each direction\n",
    "    return p_l,p_r,p_u,p_d\n",
    "\n",
    "# Motion model for Pacman\n",
    "def motion_model(g1, g2, g3, g4, pc, prev_action, allow_motion):\n",
    "    \n",
    "    ad = ar = al = au = 1\n",
    "    wl = manhattanweights(g1, g2, g3, g4, pc)\n",
    "    gl = [g1, g2, g3, g4]\n",
    "\n",
    "    # weighted sum of ghosts position in each direction\n",
    "    # higher sum, indicates ghosts closer to pacman in respective direction\n",
    "    for g, w in zip(gl, wl):\n",
    "        if g[0] > pc[0]:\n",
    "            al += w / (g[0] - pc[0] + 1e-7)\n",
    "        elif g[0] < pc[0]:\n",
    "            ar += w / (pc[0] - g[0] + 1e-7)\n",
    "        if g[1] > pc[1]:\n",
    "            au += w / (g[1] - pc[1] + 1e-7)\n",
    "        elif g[1] < pc[1]:\n",
    "            ad += w / (pc[1] - g[1] + 1e-7)\n",
    "\n",
    "    # Inverse to obtain higher values indicate more probable direction of motion\n",
    "    ad = 1 / ad\n",
    "    au = 1 / au\n",
    "    ar = 1 / ar\n",
    "    al = 1 / al\n",
    "\n",
    "    # Likely to repeat action, so scale up probability\n",
    "    if prev_action == \"r\":\n",
    "        ar = ar * 1.25\n",
    "    elif prev_action == \"l\":\n",
    "        al = al * 1.25\n",
    "    elif prev_action == \"u\":\n",
    "        au = au * 1.25\n",
    "    elif prev_action == \"d\":\n",
    "        ad = ad * 1.25\n",
    "\n",
    "    # normalize probabilities\n",
    "    sum = al + ad + au + ar\n",
    "    p_l = al / sum\n",
    "    p_r = ar / sum\n",
    "    p_u = au / sum\n",
    "    p_d = ad / sum\n",
    "\n",
    "    # Given Dictionary of allowable motions, if cannot move direction, split the probabilities to other directions\n",
    "    if allow_motion[\"u\"] == 0:\n",
    "        p_r += 0.4 * p_u\n",
    "        p_l += 0.4 * p_u\n",
    "        p_d += 0.2 * p_u\n",
    "        p_u = 0\n",
    "\n",
    "    if allow_motion[\"d\"] == 0:\n",
    "        p_r += 0.4 * p_d\n",
    "        p_l += 0.4 * p_d\n",
    "        p_u += 0.2 * p_u\n",
    "        p_d = 0\n",
    "\n",
    "    if allow_motion[\"r\"] == 0:\n",
    "        p_u += 0.4 * p_r\n",
    "        p_d += 0.4 * p_r\n",
    "        p_l += 0.2 * p_r\n",
    "        p_r = 0\n",
    "\n",
    "    if allow_motion[\"l\"] == 0:\n",
    "        p_u += 0.4 * p_l\n",
    "        p_d += 0.4 * p_l\n",
    "        p_r += 0.2 * p_l\n",
    "        p_l = 0\n",
    "\n",
    "\n",
    "    # Returns Probabilties of motion in each direction\n",
    "    return p_l, p_r, p_u, p_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Information out of the image like observation of Entity\n",
    "\n",
    "class Extract:\n",
    "    \"\"\"\n",
    "    Extracts all relevant information from the current frame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.object_colors = {\n",
    "            \"pacman\": {\"lower\": (25, 100, 100), \"upper\": (35, 255, 255)},  # Yellow\n",
    "            \"red_ghost\": [\n",
    "        {\"lower\": (0, 100, 100), \"upper\": (5, 255, 255)},   # Red range 1\n",
    "        {\"lower\": (160, 100, 100), \"upper\": (180, 255, 255)}  # Red range 2\n",
    "    ],  \n",
    "            \"cyan_ghost\": {\"lower\": (80, 100, 100), \"upper\": (100, 255, 255)},  # Cyan\n",
    "            \"pink_ghost\": {\"lower\": (110, 20, 100), \"upper\": (160, 110, 255)},  # Pink\n",
    "            \"orange_ghost\": {\"lower\": (5, 20, 100), \"upper\": (20, 255, 255)},  # Orange\n",
    "        }\n",
    "        self.ghost_marker_colors = {\n",
    "            \"pacman\": (0, 255, 255),\n",
    "            \"red_ghost\": (0, 0, 255),\n",
    "            \"cyan_ghost\": (255, 255, 0),\n",
    "            \"pink_ghost\": (255, 0, 255),\n",
    "            \"orange_ghost\": (0, 100, 255),\n",
    "        }\n",
    "        self.movements = {\n",
    "            1: \"up\",\n",
    "            -1: \"down\",\n",
    "            -10: \"left\",\n",
    "            10: \"right\",\n",
    "            11: \"upright\",\n",
    "            -11: \"downleft\",\n",
    "            9: \"upleft\",\n",
    "            -9: \"downright\",\n",
    "            0: \"nomo\",\n",
    "        }\n",
    "\n",
    "    def find_all_centers(self,mask: cv2.Mat,entity ):\n",
    "        \"\"\"\n",
    "        Find all centers of the object in the mask\n",
    "\n",
    "        Args:\n",
    "            mask: binary mask of the object\n",
    "\n",
    "        Returns:\n",
    "            centers: list of centers of the object\n",
    "        \"\"\"\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        centers = []\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                \n",
    "                # Calculate area\n",
    "                area = M[\"m00\"]\n",
    "                \n",
    "                if entity == \"pacman\":\n",
    "                    centers.append((cx,cy))\n",
    "                if area > 250 :  # Adjust thresholds as needed to only recognize entity centers\n",
    "                    centers.append((cx, cy))\n",
    "        return centers\n",
    "\n",
    "    def bgr_to_hsv(self, frame: cv2.Mat):\n",
    "        \"\"\"converts BGR image to HSV image\"\"\"\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def create_combined_mask(self, hsv_frame: cv2.Mat, color_ranges):\n",
    "        \"\"\"\n",
    "        Creates a combined mask from multiple color ranges.\n",
    "\n",
    "        Args:\n",
    "            hsv_frame: current frame in HSV.\n",
    "            color_ranges: list or dict of lower and upper HSV bounds.\n",
    "\n",
    "        Returns:\n",
    "            combined_mask: a binary mask combining all ranges.\n",
    "        \"\"\"\n",
    "        combined_mask = None\n",
    "        if isinstance(color_ranges, list):\n",
    "            for color_range in color_ranges:\n",
    "                mask = cv2.inRange(hsv_frame, np.array(color_range[\"lower\"]), np.array(color_range[\"upper\"]))\n",
    "                combined_mask = mask if combined_mask is None else cv2.bitwise_or(combined_mask, mask)\n",
    "        else:\n",
    "            combined_mask = cv2.inRange(hsv_frame, np.array(color_ranges[\"lower\"]), np.array(color_ranges[\"upper\"]))\n",
    "        return combined_mask\n",
    "\n",
    "    def extract_locations(self, frame: cv2.Mat, multi=False, remove_spawn_point=True):\n",
    "        \"\"\"\n",
    "        Extracts the locations of all objects in the frame.\n",
    "\n",
    "        Args:\n",
    "            frame: current frame in BGR.\n",
    "            multi: whether to extract multiple objects of the same type.\n",
    "            remove_spawn_point: whether to remove the spawn point from the frame.\n",
    "\n",
    "        Returns:\n",
    "            positions: dictionary containing the positions of all objects.\n",
    "        \"\"\"\n",
    "        positions = {}\n",
    "        if remove_spawn_point:\n",
    "            frame[220:240, 170:190, :] = 0\n",
    "        hsv = self.bgr_to_hsv(frame)\n",
    "\n",
    "        for name, color_ranges in self.object_colors.items():\n",
    "            combined_mask = self.create_combined_mask(hsv, color_ranges)\n",
    "            center = self.find_all_centers(combined_mask,name) \n",
    "            positions[name] = center\n",
    "\n",
    "        return positions\n",
    "\n",
    "    def extract_movement(self, positions: dict, prev_positions: dict):\n",
    "        \"\"\"\n",
    "        Extracts the movement of all objects in the frame\n",
    "\n",
    "        Args:\n",
    "            frame: current frame in BGR\n",
    "            prev_positions: dictionary containing the positions of all objects in the previous frame\n",
    "\n",
    "        Returns:\n",
    "            movements: dictionary containing the movements of all objects\n",
    "        \"\"\"\n",
    "        movements = {}\n",
    "        for name in positions:\n",
    "            if name in prev_positions:\n",
    "                prev_position = prev_positions[name]\n",
    "                if prev_position is not None and positions[name] is not None:\n",
    "                    movements[name] = self.movements[\n",
    "                        np.sign(positions[name][0] - prev_position[0]) * 10\n",
    "                        + np.sign(positions[name][1] - prev_position[1])\n",
    "                    ]\n",
    "                else:\n",
    "                    movements[name] = None\n",
    "            else:\n",
    "                movements[name] = None\n",
    "        return movements\n",
    "\n",
    "    def valid_entity_movements(self, frame: cv2.Mat, entity_center: tuple, offset=20):\n",
    "        \"\"\"\n",
    "        Checks for walls in the immediate vicinity of Pac-Man (up, down, left, right).\n",
    "\n",
    "        Args:\n",
    "            frame: Current frame in BGR\n",
    "            pacman_center: (cx, cy) center of Pac-Man\n",
    "            offset: How many pixels away from the center to check for a wall\n",
    "\n",
    "        Returns:\n",
    "            A dictionary indicating whether pacman can move in each direction.\n",
    "            e.g. {\"up\": True, \"down\": False, \"left\": True, \"right\": False}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # If we have no entity detected, just return False in all directions\n",
    "            if entity_center is None:\n",
    "                return {\"up\": False, \"down\": False, \"left\": False, \"right\": False}\n",
    "\n",
    "            hsv = self.bgr_to_hsv(frame)\n",
    "\n",
    "            # Define a rough HSV range for the blue walls\n",
    "            walls_lower = (120, 100, 30)\n",
    "            walls_upper = (130, 255, 255)\n",
    "\n",
    "            # Create a mask that highlights the walls\n",
    "            walls_mask = cv2.inRange(hsv, walls_lower, walls_upper)\n",
    "\n",
    "            cx, cy = entity_center\n",
    "            height, width = walls_mask.shape\n",
    "\n",
    "            # Safeguard boundaries\n",
    "            up_y = max(cy - offset, 0)\n",
    "            down_y = min(cy + offset, height - 1)\n",
    "            left_x = max(cx - offset, 0)\n",
    "            right_x = min(cx + offset, width - 1)\n",
    "\n",
    "            # Check pixel values in rectangle in each direction\n",
    "\n",
    "            up_wall_matrix = walls_mask[up_y : cy - 10, cx - 10 : cx + 10]\n",
    "            down_wall_matrix = walls_mask[cy + 10 : down_y, cx - 10 : cx + 10]\n",
    "            left_wall_matrix = walls_mask[cy - 10 : cy + 10, left_x : cx - 10]\n",
    "            right_wall_matrix = walls_mask[cy - 10 : cy + 10, cx + 10 : right_x]\n",
    "\n",
    "            # Boolean values for if Entity blocked by wall in a direction\n",
    "            up_wall = ~np.any(up_wall_matrix)\n",
    "            down_wall = ~np.any(down_wall_matrix)\n",
    "            left_wall = ~np.any(left_wall_matrix)\n",
    "            right_wall = ~np.any(right_wall_matrix)\n",
    "\n",
    "            return {\n",
    "                \"up\": up_wall,\n",
    "                \"down\": down_wall,\n",
    "                \"left\": left_wall,\n",
    "                \"right\": right_wall,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(entity_center)\n",
    "            return {\"up\": False, \"down\": False, \"left\": False, \"right\": False}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParticleFilter for Pac-Man\n",
    "\n",
    "\n",
    "class ParticleFilter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_particles,\n",
    "        frame_width,\n",
    "        frame_height,\n",
    "        extract_instance,\n",
    "        spawn_point=(190, 315),\n",
    "        init_prev_action=\"r\",\n",
    "        init_method=\"random\",\n",
    "        resample_method=\"multinomial\",\n",
    "        no_detection_randomise=False,\n",
    "        motion_noise_std=3.0,  # <--- Gaussian noise for motion\n",
    "        measurement_noise_px=2,  # <--- Pixel noise for measurements\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Particle Filter for tracking Pac-Man\n",
    "\n",
    "        Args:\n",
    "            num_particles (int): Number of particles\n",
    "            frame_width (int): Width of the game frame\n",
    "            frame_height (int): Height of the game frame\n",
    "            extract_instance (Extract): An instance of the Extract class\n",
    "            init_prev_action (str): An initial guess for Pac-Man's previous action\n",
    "            init_method (str): Method to initialize particles ('random' or 'center')\n",
    "            no_detection_randomise (bool): Whether to randomize particles in case of no detection\n",
    "            motion_noise_std (float): Standard deviation of the Gaussian noise added\n",
    "                                      to each motion step\n",
    "            measurement_noise_px (int): Max random integer offset added to each\n",
    "                                        measured detection location\n",
    "        \"\"\"\n",
    "        self.num_particles = num_particles\n",
    "        self.frame_width = frame_width\n",
    "        self.frame_height = frame_height\n",
    "        self.extract = extract_instance\n",
    "        self.init_prev_action = init_prev_action\n",
    "        self.init_method = init_method\n",
    "        self.no_detection_randomise = no_detection_randomise\n",
    "        self.spawn_point = spawn_point\n",
    "        self.resample_method = resample_method\n",
    "        self.motion_noise_std = motion_noise_std\n",
    "        self.measurement_noise_px = measurement_noise_px\n",
    "\n",
    "        # Each particle: (x, y, prev_action)\n",
    "        self.entities = [\"pacman\", \"red_ghost\", \"cyan_ghost\", \"pink_ghost\", \"orange_ghost\"]\n",
    "        self.particles = {entity: [] for entity in self.entities}\n",
    "        self.weights = {entity: np.ones(num_particles, dtype=np.float32) / num_particles for entity in self.entities}\n",
    "\n",
    "        for entity in self.entities:\n",
    "            self.initialize_particles(entity)\n",
    "\n",
    "    def initialize_particles(self,entity):\n",
    "        \"\"\"Initialize particles in the valid region of the frame.\"\"\"\n",
    "        self.particles[entity] = []\n",
    "        for _ in range(self.num_particles):\n",
    "            if self.init_method == \"random\":\n",
    "                x = random.randint(0, self.frame_width - 1)\n",
    "                y = random.randint(0, self.frame_height - 1)\n",
    "            elif self.init_method == \"center\":\n",
    "                x = self.frame_width // 2\n",
    "                y = self.frame_height // 2\n",
    "            elif self.init_method == \"spawn_point\" and entity == \"pacman\":\n",
    "                if random.random() < 0.5:\n",
    "                    x = random.randint(\n",
    "                        self.spawn_point[0] - 40, self.spawn_point[0] + 50\n",
    "                    )\n",
    "                    y = random.randint(\n",
    "                        self.spawn_point[1] - 25, self.spawn_point[1] + 25\n",
    "                    )\n",
    "                else:\n",
    "                    x = random.randint(0, self.frame_width - 1)\n",
    "                    y = random.randint(0, self.frame_height - 1)\n",
    "            else:\n",
    "                x = random.randint(0, self.frame_width - 1)\n",
    "                y = random.randint(0, self.frame_height - 1)\n",
    "\n",
    "            self.particles[entity].append((x, y, self.init_prev_action))\n",
    "\n",
    "        self.particles[entity] = np.array(self.particles[entity], dtype=object)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def step(self, frame, prev_frame_positions):\n",
    "        \"\"\"\n",
    "        Main PF step for one iteration.\n",
    "\n",
    "        1) Extract ghost positions from the current frame\n",
    "        2) Determine allowed movements for Entity's (walls, etc.)\n",
    "        3) Motion update: apply motion_model to each particle + motion noise\n",
    "        4) Observation update: weigh each particle by how well it matches the detection\n",
    "           (with measurement noise)\n",
    "        5) Resample\n",
    "        6) Estimate the best Entity's position from the particles\n",
    "\n",
    "        Args:\n",
    "            frame (np.ndarray): Current game frame (BGR)\n",
    "            prev_frame_positions (dict): Positions from the previous frame\n",
    "                                         \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        ghost_keys = [\"red_ghost\", \"cyan_ghost\", \"pink_ghost\", \"orange_ghost\"]\n",
    "        \n",
    "        # Best Guess for Pacman\n",
    "        if prev_frame_positions and prev_frame_positions.get(\"pacman\") is not None:\n",
    "            # Might be a list of centers or a single center\n",
    "            prev_pacman_pos = prev_frame_positions[\"pacman\"]\n",
    "            if len(prev_pacman_pos) == 0:\n",
    "                px = int(np.mean(self.particles[\"pacman\"][:, 0]))\n",
    "                py = int(np.mean(self.particles[\"pacman\"][:, 1]))\n",
    "                best_guess_pacman = (px, py)\n",
    "            elif isinstance(prev_pacman_pos, list) and len(prev_pacman_pos) > 0:\n",
    "                best_guess_pacman = prev_pacman_pos[0]\n",
    "            else:\n",
    "                best_guess_pacman = prev_pacman_pos\n",
    "        else:\n",
    "            # If no info, compute average of the current particles\n",
    "            px = int(np.mean(self.particles[\"pacman\"][:, 0]))\n",
    "            py = int(np.mean(self.particles[\"pacman\"][:, 1]))\n",
    "            best_guess_pacman = (px, py)\n",
    "\n",
    "\n",
    "        # Best Guess for all Ghosts\n",
    "        ghostspos = {}\n",
    "        for gkey in ghost_keys:\n",
    "            if prev_frame_positions and prev_frame_positions.get(gkey) is not None and self.particles[gkey] is not None:\n",
    "                \n",
    "                # Might be a list of centers or a single center\n",
    "                prev_ghost_pos = prev_frame_positions[gkey]\n",
    "                if prev_ghost_pos is not None and isinstance(prev_ghost_pos, list) and len(prev_ghost_pos) > 0:\n",
    "                    bestgpos = prev_ghost_pos[0]\n",
    "                else:\n",
    "                    bestgpos = prev_ghost_pos\n",
    "            else:\n",
    "                # If no info, compute average of the current particles\n",
    "                if self.particles[gkey] is not None:\n",
    "                    px = int(np.mean(self.particles[gkey][:, 0]))\n",
    "                    py = int(np.mean(self.particles[gkey][:, 1]))\n",
    "                    bestgpos = (px, py)\n",
    "                else:\n",
    "                    bestgpos = None\n",
    "            ghostspos[gkey] = bestgpos\n",
    "\n",
    "        # Compute allowable direction of motion for each entity based on best guess\n",
    "        allow_dict = self._compute_allow_dict(frame, best_guess_pacman)\n",
    "        ghostallow = {}\n",
    "        for gkey in ghost_keys:\n",
    "            ghostallow[gkey] = self._compute_allow_dict(frame, ghostspos[gkey])\n",
    "            \n",
    "        ghosts = []\n",
    "        for gkey in ghost_keys:\n",
    "            \n",
    "            if len(ghostspos[gkey]) == 0 :\n",
    "                ghosts.append((999,999)) \n",
    "                # If no Ghost in previous frame\n",
    "            else:\n",
    "                ghosts.append(ghostspos[gkey])\n",
    "\n",
    "        # Motion Update for Each Entity\n",
    "        self._motion_update(ghosts, allow_dict)\n",
    "        for gkey in ghost_keys:\n",
    "            if self.particles[gkey] is not None:\n",
    "                self.ghost_motion(gkey,best_guess_pacman,ghostallow[gkey])\n",
    "        motion_update_positions = self.particles.copy()\n",
    "        \n",
    "        # Observation Update for Each Entity\n",
    "        positions = {}\n",
    "        for entity in self.entities:\n",
    "            positions[entity] = self._observation_update(frame,entity)\n",
    "            \n",
    "        \n",
    "        # Resample all particles\n",
    "        for entity in self.entities:\n",
    "            if self.particles[entity] is not None:\n",
    "                self._resample(entity,method=self.resample_method)\n",
    "        observation_update_positions = self.particles.copy()\n",
    "\n",
    "        # Compute best estimate of all particles\n",
    "        best_estimate = {}\n",
    "        for entity in self.entities:\n",
    "            if self.particles[entity] is not None:\n",
    "                best_estimate[entity] = self.estimate(entity)\n",
    "            else:\n",
    "                best_estimate[entity] = None\n",
    "\n",
    "        return best_estimate, positions,motion_update_positions,observation_update_positions\n",
    "\n",
    "    def ghost_motion(self,ghost,pc,allow_motion_dict):\n",
    "        \n",
    "        updated_particles = []\n",
    "        for i, (x, y, prev_act) in enumerate(self.particles[ghost]):\n",
    "            ghostposition = (x, y)\n",
    "            # motion_model returns p_left, p_right, p_up, p_down\n",
    "            p_l, p_r, p_u, p_d = motion_model_ghosts(\n",
    "                ghostposition,pc,prev_act,allow_motion_dict\n",
    "            )\n",
    "\n",
    "            # Normalize if necessary\n",
    "            probs = np.array([p_l, p_r, p_u, p_d])\n",
    "            probs_sum = probs.sum()\n",
    "            if probs_sum > 0:\n",
    "                probs /= probs_sum\n",
    "            else:\n",
    "                # fallback: uniform\n",
    "                probs = np.ones(4) / 4.0\n",
    "            action = np.random.choice([\"l\", \"r\", \"u\", \"d\"], p=probs)\n",
    "\n",
    "            # Move the particle\n",
    "            new_x, new_y = x, y\n",
    "            if action == \"l\":\n",
    "                new_x = x - 2\n",
    "            elif action == \"r\":\n",
    "                new_x = x + 2\n",
    "            elif action == \"u\":\n",
    "                new_y = y - 2\n",
    "            elif action == \"d\":\n",
    "                new_y = y + 2\n",
    "\n",
    "            # Clamp bounds\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y))\n",
    "            \n",
    "\n",
    "            # Add motion noise (Gaussian).\n",
    "            # Clamp again in case noise pushes it out of bounds.\n",
    "            noise_dx = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            noise_dy = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x + noise_dx))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y + noise_dy))    \n",
    "\n",
    "            updated_particles.append((new_x, new_y, action))\n",
    "\n",
    "        # Change Particle Set to newly modified set baed on movement\n",
    "        self.particles[ghost] = np.array(updated_particles, dtype=object)\n",
    "        \n",
    "    def _motion_update(self, ghosts, allow_motion_dict):\n",
    "        \n",
    "        updated_particles = []\n",
    "        for i, (x, y, prev_act) in enumerate(self.particles[\"pacman\"]):\n",
    "            pc = (x, y)\n",
    "            g1, g2, g3, g4 = ghosts\n",
    "            # motion_model returns p_left, p_right, p_up, p_down\n",
    "            p_l, p_r, p_u, p_d = motion_model(\n",
    "                g1, g2, g3, g4, pc, prev_act, allow_motion_dict\n",
    "            )\n",
    "\n",
    "            # Normalize if necessary\n",
    "            probs = np.array([p_l, p_r, p_u, p_d])\n",
    "            probs_sum = probs.sum()\n",
    "            if probs_sum > 0:\n",
    "                probs /= probs_sum\n",
    "            else:\n",
    "                # fallback: uniform\n",
    "                probs = np.ones(4) / 4.0\n",
    "\n",
    "            action = np.random.choice([\"l\", \"r\", \"u\", \"d\"], p=probs)\n",
    "\n",
    "            # Move the particle\n",
    "            new_x, new_y = x, y\n",
    "            if action == \"l\":\n",
    "                new_x = x - 2\n",
    "            elif action == \"r\":\n",
    "                new_x = x + 2\n",
    "            elif action == \"u\":\n",
    "                new_y = y - 2\n",
    "            elif action == \"d\":\n",
    "                new_y = y + 2\n",
    "\n",
    "            # Clamp bounds\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y))\n",
    "\n",
    "            # Add motion noise (Gaussian).\n",
    "            # Clamp again in case noise pushes it out of bounds.\n",
    "            noise_dx = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            noise_dy = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x + noise_dx))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y + noise_dy))\n",
    "\n",
    "            updated_particles.append((new_x, new_y, action))\n",
    "\n",
    "        self.particles[\"pacman\"] = np.array(updated_particles, dtype=object)\n",
    "\n",
    "    def _observation_update(self, frame,entity):\n",
    "        \"\"\"\n",
    "        Weigh each particle by how well it matches the detected positions of Entity.\n",
    "        If multiple centers are found, we split probability among them.\n",
    "\n",
    "        Adds measurement noise by artificially jittering the positions we get from\n",
    "        extract_locations. This simulates uncertain detection.\n",
    "        \"\"\"\n",
    "        positions = self.extract.extract_locations(\n",
    "            frame, multi=True, remove_spawn_point=False\n",
    "        )\n",
    "        entity_centers = positions[entity]\n",
    "\n",
    "        # If no detection, randomize few particles \n",
    "        if self.no_detection_randomise and not entity_centers:\n",
    "            for i, particle in enumerate(self.particles[entity]):\n",
    "                if random.random() < 0.3:\n",
    "                    particle[0] = random.randint(0, self.frame_width - 1)\n",
    "                    particle[1] = random.randint(0, self.frame_height - 1)\n",
    "                    self.weights[entity][i] *= 0.1\n",
    "                else:\n",
    "                    self.weights[entity][i] *= 0.8\n",
    "            return \n",
    "        \n",
    "        #  If no detection, only reduce the weights\n",
    "        if not self.no_detection_randomise and not entity_centers:\n",
    "            self.weights[entity] *= 0.1\n",
    "            return \n",
    "        \n",
    "        if self.particles[entity] is None:\n",
    "            self.weights[entity] *= 0.8\n",
    "            return \n",
    "\n",
    "        # Inject measurement noise into each detected center\n",
    "        noisy_centers = []\n",
    "        for c in entity_centers:\n",
    "            # small random offset in x and y\n",
    "            # ± self.measurement_noise_px\n",
    "            nx = c[0] + random.randint(\n",
    "                -self.measurement_noise_px, self.measurement_noise_px\n",
    "            )\n",
    "            ny = c[1] + random.randint(\n",
    "                -self.measurement_noise_px, self.measurement_noise_px\n",
    "            )\n",
    "            # clamp to bounds\n",
    "            nx = max(0, min(self.frame_width - 1, nx))\n",
    "            ny = max(0, min(self.frame_height - 1, ny))\n",
    "            noisy_centers.append((nx, ny))\n",
    "\n",
    "        match_threshold = 15\n",
    "        num_centers = len(noisy_centers)\n",
    "        center_prob = 1.0 / num_centers\n",
    "\n",
    "        for i, (x, y, _) in enumerate(self.particles[entity]):\n",
    "            # Find distance to the closest noisy center\n",
    "            min_dist = float(\"inf\")\n",
    "            for c in noisy_centers:\n",
    "                dist = np.hypot(x - c[0], y - c[1])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "\n",
    "            if min_dist < match_threshold:\n",
    "                # The closer, the higher the weighting\n",
    "                self.weights[entity][i] *= (\n",
    "                    1.0 + center_prob * (match_threshold - min_dist) / match_threshold\n",
    "                )\n",
    "            else:\n",
    "                # If cant be associated, weight is reduced\n",
    "                self.weights[entity][i] *= 0.5\n",
    "\n",
    "        # Normalize weights\n",
    "        weight_sum = np.sum(self.weights[entity])\n",
    "        if weight_sum > 0:\n",
    "            self.weights[entity] /= weight_sum\n",
    "        else:\n",
    "            self.weights[entity][:] = 1.0 / len(self.weights[entity])\n",
    "\n",
    "        return positions[entity]\n",
    "\n",
    "    def _resample(self, entity,method=\"multinomial\"):\n",
    "        \"\"\"\n",
    "        Systematic or multinomial resampling of the particles\n",
    "        based on current weights.\n",
    "        \"\"\"\n",
    "        N = self.num_particles\n",
    "        new_particles = []\n",
    "        # normalized weights\n",
    "        self.weights[entity] = self.weights[entity] / np.sum(self.weights[entity])\n",
    "\n",
    "        if method == \"multinomial\":\n",
    "            indices = np.random.choice(range(N), size=N, p=self.weights[entity])\n",
    "            for idx in indices:\n",
    "                new_particles.append(self.particles[entity][idx])\n",
    "\n",
    "            self.particles[entity] = np.array(new_particles, dtype=object)\n",
    "            self.weights[entity] = np.ones(N, dtype=np.float32) / N\n",
    "        elif method == \"systematic\":\n",
    "            indices = np.zeros(N, dtype=int)\n",
    "            r = np.random.rand() / N\n",
    "            c = self.weights[entity][0]\n",
    "            i = 0\n",
    "            for m in range(N - 1):\n",
    "                U = r + m / N\n",
    "                while U > c:\n",
    "                    i += 1\n",
    "                    c += self.weights[entity][i]\n",
    "                indices[m] = i\n",
    "\n",
    "            for idx in indices:\n",
    "                new_particles.append(self.particles[entity][idx])\n",
    "\n",
    "            self.particles[entity] = np.array(new_particles, dtype=object)\n",
    "            self.weights[entity] = np.ones(N, dtype=np.float32) / N\n",
    "\n",
    "    def estimate(self,entity):\n",
    "        \"\"\"\n",
    "        Estimate Entity's position from the particles \n",
    "        Returns:\n",
    "            (est_x, est_y)\n",
    "        \"\"\"\n",
    "        if self.weights[entity].sum() < 1e-7:\n",
    "            # Fallback\n",
    "            est_x = int(np.mean(self.particles[entity][:, 0]))\n",
    "            est_y = int(np.mean(self.particles[entity][:, 1]))\n",
    "            return (est_x, est_y)\n",
    "\n",
    "        # Weighted average\n",
    "        w_norm = self.weights[entity] / self.weights[entity].sum()\n",
    "        est_x = int(np.sum(self.particles[entity][:, 0] * w_norm))\n",
    "        est_y = int(np.sum(self.particles[entity][:, 1] * w_norm))\n",
    "        return (est_x, est_y)\n",
    "\n",
    "    def _compute_allow_dict(self, frame, entity_center):\n",
    "        \"\"\"\n",
    "        Returns Dictionary of Possible Movements for an Entity\n",
    "        \"\"\"\n",
    "        valid_moves = self.extract.valid_entity_movements(frame, entity_center)\n",
    "        allow_dict = {\n",
    "            \"u\": 1 if valid_moves[\"up\"] else 0,\n",
    "            \"d\": 1 if valid_moves[\"down\"] else 0,\n",
    "            \"l\": 1 if valid_moves[\"left\"] else 0,\n",
    "            \"r\": 1 if valid_moves[\"right\"] else 0,\n",
    "        }\n",
    "        return allow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extract = Extract()  \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"4m.mp4\")\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "video_filename = \"kidnapcase.avi\"  \n",
    "frame_width, frame_height = frame_width, frame_height  \n",
    "fps = 10  \n",
    "fps = 30  \n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")  \n",
    "out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "no_of_particles = 500\n",
    "init_method = \"random\"\n",
    "resample_method = \"systematic\"\n",
    "\n",
    "# Testing Randomize On for No Detection\n",
    "pf1 = ParticleFilter(\n",
    "    num_particles=no_of_particles,\n",
    "    frame_width=frame_width,\n",
    "    frame_height=frame_height,\n",
    "    extract_instance=extract,\n",
    "    init_prev_action=\"r\",\n",
    "    init_method=init_method,\n",
    "    no_detection_randomise=True,\n",
    "    resample_method=resample_method,\n",
    "    motion_noise_std=5,  \n",
    "    measurement_noise_px=10,  \n",
    ")\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"pacman\": (0, 255, 255),       # Yellow\n",
    "    \"red_ghost\": (0, 0, 255),      # Red\n",
    "    \"cyan_ghost\": (255, 255, 0),   # Cyan\n",
    "    \"pink_ghost\": (255, 0, 0),     # Pink\n",
    "    \"orange_ghost\": (0, 165, 255)  # Orange\n",
    "}\n",
    "\n",
    "colors_best_estimate = {\n",
    "    \"pacman\": (0, 120, 120),       # Yellow\n",
    "    \"red_ghost\": (255, 0, 255),      # Red\n",
    "    \"cyan_ghost\": (255, 0, 0),   # Cyan\n",
    "    \"pink_ghost\": (255, 255, 0),   # Pink\n",
    "    \"orange_ghost\": (0, 0, 255)  # Orange\n",
    "}\n",
    "\n",
    "prev_positions = None\n",
    "innovations1 = {entity: [] for entity in [\"pacman\"]}\n",
    "variances1 = {entity: [] for entity in [\"pacman\"]}\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    best_estimates, positions,motion_update,observation_update = pf1.step(frame, prev_positions)\n",
    "\n",
    "    for entity in innovations1.keys():\n",
    "        total_mean_distance = np.sum(np.abs(motion_update[entity][:, :2] - observation_update[entity][:, :2]))\n",
    "        innovations1[entity].append(total_mean_distance)\n",
    "        if pf1.particles[entity].size > 0:\n",
    "            variance = np.var(pf1.particles[entity][:, :2], axis=0).sum()\n",
    "            variances1[entity].append(variance)\n",
    "\n",
    "    for entity in pf1.entities:\n",
    "        if best_estimates[entity] is not None:\n",
    "            entity_particles = pf1.particles[entity]\n",
    "            for x, y, _ in entity_particles:\n",
    "                cv2.circle(frame, (x, y), 1, colors[entity], -1)\n",
    "            best_estimate = best_estimates[entity]\n",
    "            cv2.circle(frame, best_estimate, 7, colors_best_estimate[entity], -1)\n",
    "\n",
    "            if positions and positions.get(entity, None):\n",
    "                if isinstance(positions[entity], list):\n",
    "                    for c in positions[entity]:\n",
    "                        cv2.circle(frame, c, 5, colors[entity], 2)\n",
    "                elif positions[entity] is not None:\n",
    "                    cv2.circle(frame, positions[entity], 5, colors[entity], 2)\n",
    "\n",
    "    prev_positions = positions\n",
    "    \n",
    "    cv2.imshow(\"Pacman Tracking PF (with noise)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break  # Esc to quit\n",
    "    print(\"Best Estimate Locations:\")\n",
    "    for entity in pf1.entities:\n",
    "        print(f\"{entity.capitalize()}: {best_estimates[entity]}\")\n",
    "        if positions and positions.get(entity, None):\n",
    "            print(f\"Detected {entity.capitalize()} Locations: {positions[entity]}\")\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "entity_colors = {\n",
    "\"pacman\": (0.0, 0.47, 0.47),       # Scaled from (0, 120, 120) BGR\n",
    "\"red_ghost\": (1.0, 0.0, 1.0),      # Scaled from (255, 0, 255)\n",
    "\"cyan_ghost\": (1.0, 0.0, 0.0),     # Scaled from (255, 0, 0)\n",
    "\"pink_ghost\": (1.0, 1.0, 0.0),     # Scaled from (255, 255, 0)\n",
    "\"orange_ghost\": (0.0, 0.0, 1.0)    # Scaled from (0, 0, 255)\n",
    "}\n",
    "# Plot innovation graphs for each entity\n",
    "plt.figure()\n",
    "\n",
    "entity_legend = {\n",
    "\"pacman\": \"pacman\",       # Scaled from (0, 120, 120) BGR\n",
    "\"red_ghost\": \"red\",      # Scaled from (255, 0, 255)\n",
    "\"cyan_ghost\": \"cyan\",     # Scaled from (255, 0, 0)\n",
    "\"pink_ghost\": \"pink\",     # Scaled from (255, 255, 0)\n",
    "\"orange_ghost\": \"orange\"    # Scaled from (0, 0, 255)\n",
    "} \n",
    "\n",
    "plt.figure()\n",
    "for entity in innovations1.keys():\n",
    "    plt.plot(np.array(innovations1[entity]) / no_of_particles, label=f\"Randomize True \", color=\"r\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Innovation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot variance graphs\n",
    "plt.figure()\n",
    "for entity in variances1.keys():\n",
    "    plt.plot(np.array(variances1[entity])/no_of_particles, label=f\"Randomize True \", linestyle='--', color=\"r\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Particle Variance\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
